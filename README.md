# SRE Monitoring Suite (Python)

![Tests](https://github.com/Iriome-Santana/sre-monitoring-suite/actions/workflows/tests.yml/badge.svg)
![Python Version](https://img.shields.io/badge/python-3.12-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![Coverage](https://img.shields.io/badge/coverage-91%25-brightgreen)

Sistema de monitoreo local desarrollado en Python para supervisar
uso de CPU, memoria RAM y disco, con alertas autom√°ticas y
gesti√≥n de estado para evitar alertas repetidas.

Proyecto orientado a pr√°cticas reales de Site Reliability Engineering:
observabilidad, alerting, automatizaci√≥n y respuesta a incidentes.


## Table of Contents
- Problem Statement
- Features
- Observability Stack
- Quick Start
- Architecture
- Production Readiness
- Installation
- Configuration

## Problem Statement

En muchos sistemas peque√±os o personales no existe monitoreo b√°sico.
Los problemas (disco lleno, CPU saturada, fuga de memoria) se detectan
cuando el sistema ya est√° degradado o ca√≠do.

Este proyecto busca:
- Detectar problemas de recursos antes del fallo
- Evitar alertas repetidas (alert fatigue)
- Enviar notificaciones claras y accionables
- Automatizar la supervisi√≥n con herramientas simples

## Features

- Monitoreo de CPU basado en idle time (top)
- Monitoreo de memoria usando memoria disponible real (free)
- Monitoreo de uso de disco por path configurable (df)
- Umbrales configurables v√≠a variables de entorno
- Gesti√≥n de estado para detectar cambios (OK ‚Üí WARNING ‚Üí CRITICAL)
- Alertas y recoveries enviados a Discord
- Logs detallados por cada ejecuci√≥n
- Scripts de testing manual
- Reporte diario agregado
- Limpieza autom√°tica de logs antiguos

## üìä Visualizaci√≥n con Grafana

Este proyecto incluye un stack completo de observabilidad con Prometheus y Grafana para visualizaci√≥n de m√©tricas en tiempo real.

### Dashboard

El dashboard muestra:
- **Uso de disco**: Gr√°fico de l√≠nea con tendencia temporal
- **Memoria disponible**: Gauge con thresholds de color (rojo < 20%, amarillo 20-40%, verde > 40%)
- **CPU idle**: Gr√°fico de l√≠nea mostrando porcentaje de CPU disponible

![Dashboard de Grafana](docs/dashboard-screenshot.png)

### Arquitectura de Observabilidad
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ metrics_exporter ‚îÇ ‚Üí Recolecta m√©tricas del sistema cada 15s
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ HTTP :8000/metrics
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Prometheus     ‚îÇ ‚Üí Almacena time-series data
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ PromQL queries
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Grafana      ‚îÇ ‚Üí Visualizaci√≥n en dashboards
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Inicio R√°pido
```bash
# 1. Iniciar exporter de m√©tricas
python3 src/metrics_exporter.py &

# 2. Iniciar Prometheus y Grafana con Docker Compose
docker-compose up -d

# 3. Acceder a los servicios
# - M√©tricas raw: http://localhost:8000/metrics
# - Prometheus UI: http://localhost:9090
# - Grafana: http://localhost:3000 (admin/admin)
```

### Detener servicios
```bash
# Detener Prometheus y Grafana
docker-compose down

# Detener exporter
pkill -f metrics_exporter.py
```
```

## üèóÔ∏è Arquitectura del C√≥digo

### Patr√≥n de Dise√±o

Este proyecto usa el patr√≥n **Template Method** con una clase base `BaseCheck`:
```python
from base_check import BaseCheck

check = BaseCheck("disk")
check.validate_thresholds(80, 90)
# ... l√≥gica espec√≠fica
exit_code = check.handle_state_change(state, "Disco", "85%")
```

**Ventajas:**
- DRY (Don't Repeat Yourself)
- F√°cil de extender (a√±adir nuevos checks)
- L√≥gica com√∫n centralizada
- Cada check es independiente

### A√±adir un Nuevo Check

Para crear `network_check.py` (por ejemplo):

1. Importar `BaseCheck`
2. Implementar l√≥gica espec√≠fica
3. Usar `handle_state_change()` para gestionar estado
4. Listo
```python
from base_check import BaseCheck
import subprocess

check = BaseCheck("network")
# l√≥gica aqu√≠
result = subprocess.run(["ping", "-c", "1", "8.8.8.8"], ...)
# Determinar estado
exit_code = check.handle_state_change(state, "Latencia", "50ms")
sys.exit(exit_code)
```

## Architecture

Cada check funciona de manera independiente:

check.py
  ‚îú‚îÄ‚îÄ Recolecta m√©tricas del sistema
  ‚îú‚îÄ‚îÄ Eval√∫a umbrales
  ‚îú‚îÄ‚îÄ Compara con el √∫ltimo estado
  ‚îú‚îÄ‚îÄ Decide si alertar o recuperar
  ‚îú‚îÄ‚îÄ Env√≠a notificaci√≥n
  ‚îî‚îÄ‚îÄ Guarda el nuevo estado

El m√≥dulo notifier abstrae el env√≠o de alertas
y permite a√±adir nuevos canales f√°cilmente.

## When to use this

- Sistemas peque√±os
- Servidores personales
- Laboratorios
- Entornos sin herramientas de monitoreo dedicadas

## Production Readiness Gap Analysis

Este proyecto es educativo. Aqu√≠ est√° lo que cambiar√≠a para producci√≥n real:

### ‚úÖ Lo que YA est√° production-ready:

1. **State management** - Evita alertas duplicadas (cr√≠tico)
2. **Exit codes** - Siguen est√°ndares de monitoreo
3. **Logging estructurado** - Parseable, con timestamps
4. **Separaci√≥n de concerns** - F√°cil mantener
5. **M√©tricas Hist√≥ricas** - M√©tricas con dashboard visuales

### ‚ö†Ô∏è Lo que falta para producci√≥n:

1. **High Availability**
   - **Problema:** Si este script muere, no hay alertas
   - **Soluci√≥n:** Systemd service con auto-restart
   - **Trade-off:** M√°s complejidad vs m√°s confiabilidad

2. **Secrets Management**
   - **Problema:** Webhook en archivo plano
   - **Soluci√≥n:** HashiCorp Vault o AWS Secrets Manager
   - **Trade-off:** Gratis pero inseguro vs Seguro pero cuesta tiempo/$$

3. **Monitoring del Monitoring**
   - **Problema:** ¬øQui√©n monitorea el monitor? (Deadman's switch)
   - **Soluci√≥n:** Heartbeat a servicio externo cada 10 min
   - **Trade-off:** Complejidad adicional

4. **Escalamiento**
   - **Problema:** Solo monitorea 1 servidor
   - **Soluci√≥n:** Agent en cada servidor + collector central
   - **Trade-off:** Funciona para aprender vs No escala

### üéØ Priorizando:

Si tuviera que llevar esto a producci√≥n MA√ëANA con tiempo limitado:

**Must-have (1-2 d√≠as):**
1. Systemd service (HA)
2. Secrets en variables de entorno (no en archivo)
3. Deadman's switch (cron job cada 10 min que hace ping a healthchecks.io)

**Nice-to-have (1 semana):**
4. Runbooks documentados
5. Tests automatizados

**Future (1 mes+):**
6. Multi-server support
7. Dashboard web
8. Integraci√≥n con PagerDuty

### Por Qu√© Este Orden:

- **HA primero** - Sin el monitor, est√°s ciego
- **Secrets segundo** - Vulnerabilidad de seguridad obvia
- **Deadman tercero** - "¬øQui√©n vigila al vigilante?"

**Esta priorizaci√≥n NO puede hacerla una IA** - requiere entender:
- Riesgos de negocio
- Budget disponible
- Skills del equipo
- Urgencia vs importancia


## Installation

```bash
git clone https://github.com/Iriome-Santana/sre-monitoring-suite.git
cd sre-monitoring-suite
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt


---

## üîß Configuration (MUY IMPORTANTE)

```md
## Configuration

Las siguientes variables de entorno controlan el comportamiento:

- WARNING: umbral de warning
- CRITICAL: umbral cr√≠tico
- DISCORD_WEBHOOK: webhook de Discord
- DISK_PATH: path a monitorear (por defecto /)
- NOTIFICATIONS_ENABLED: true/false
- METRICS_PORT = Puerto de las m√©tricas
- SCRAPE_INTERVAL = Intervalo de tiempo en segundos para escrapear m√©tricas

## Run manually

```bash
python src/cpu_check.py
python src/memory_check.py
python src/disk_check.py


---

## ‚è±Ô∏è Automation (CRON)

```md
## Automation (cron)

Ejecutar cada 5 minutos:

```bash
*/5 * * * * python3 /path/src/cpu_check.py >> ~/sre/logs/cpu_check.log 2>&1


---

## üìä Daily Report

```md
## Daily Report

El script `daily_report.sh` genera un resumen diario
con m√©tricas agregadas a partir de los logs.
